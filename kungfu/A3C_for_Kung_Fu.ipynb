{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# A3C for Kung Fu"
   ],
   "metadata": {
    "id": "dIo6Zkp7U1Hq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 0 - Installing the required packages and importing the libraries"
   ],
   "metadata": {
    "id": "pz8ogVxGVB6b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Installing Gymnasium"
   ],
   "metadata": {
    "id": "CqN2IEX1VKzi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbnq3XpoKa_7"
   },
   "outputs": [],
   "source": [
    "!pip install gymnasium\n",
    "!pip install \"gymnasium[atari, accept-rom-license]\"\n",
    "!apt-get install -y swig\n",
    "!pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing the libraries"
   ],
   "metadata": {
    "id": "BrsNHNQqVZLK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ho_25-9_9qnu",
    "ExecuteTime": {
     "end_time": "2024-04-11T12:57:41.856246Z",
     "start_time": "2024-04-11T12:57:40.761683Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributions as distributions\n",
    "from torch.distributions import Categorical\n",
    "import gymnasium as gym\n",
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.spaces import Box"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1 - Building the AI"
   ],
   "metadata": {
    "id": "VF6EFSGUVlk2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating the architecture of the Neural Network"
   ],
   "metadata": {
    "id": "qyNc8cxbZCYP"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "  \n",
    "  def __init__(self, action_size):\n",
    "    super(Network, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=4, out_channels=32, kernel_size=(3, 3), stride=2),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=2),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=2),\n",
    "      nn.ReLU(),\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc1 = nn.Linear(512, 128)\n",
    "    self.fc2a = nn.Linear(128, action_size)\n",
    "    self.fc2s = nn.Linear(128, 1)\n",
    "      \n",
    "  def forward(self, state):\n",
    "    x = self.conv(state)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    action_values = self.fc2a(x)\n",
    "    state_value = self.fc2s(x)\n",
    "    return action_values, state_value\n",
    "      "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T13:52:20.781907Z",
     "start_time": "2024-04-11T13:52:20.776067Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2 - Training the AI"
   ],
   "metadata": {
    "id": "eF5bETqbZbCG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up the environment"
   ],
   "metadata": {
    "id": "3C2ydyKLZgaK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class PreprocessAtari(ObservationWrapper):\n",
    "\n",
    "  def __init__(self, env, height = 42, width = 42, crop = lambda img: img, dim_order = 'pytorch', color = False, n_frames = 4):\n",
    "    super(PreprocessAtari, self).__init__(env)\n",
    "    self.img_size = (height, width)\n",
    "    self.crop = crop\n",
    "    self.dim_order = dim_order\n",
    "    self.color = color\n",
    "    self.frame_stack = n_frames\n",
    "    n_channels = 3 * n_frames if color else n_frames\n",
    "    obs_shape = {'tensorflow': (height, width, n_channels), 'pytorch': (n_channels, height, width)}[dim_order]\n",
    "    self.observation_space = Box(0.0, 1.0, obs_shape)\n",
    "    self.frames = np.zeros(obs_shape, dtype = np.float32)\n",
    "\n",
    "  def reset(self):\n",
    "    self.frames = np.zeros_like(self.frames)\n",
    "    obs, info = self.env.reset()\n",
    "    self.update_buffer(obs)\n",
    "    return self.frames, info\n",
    "\n",
    "  def observation(self, img):\n",
    "    img = self.crop(img)\n",
    "    img = cv2.resize(img, self.img_size)\n",
    "    if not self.color:\n",
    "      if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img.astype('float32') / 255.\n",
    "    if self.color:\n",
    "      self.frames = np.roll(self.frames, shift = -3, axis = 0)\n",
    "    else:\n",
    "      self.frames = np.roll(self.frames, shift = -1, axis = 0)\n",
    "    if self.color:\n",
    "      self.frames[-3:] = img\n",
    "    else:\n",
    "      self.frames[-1] = img\n",
    "    return self.frames\n",
    "\n",
    "  def update_buffer(self, obs):\n",
    "    self.frames = self.observation(obs)\n",
    "\n",
    "def make_env():\n",
    "  env = gym.make(\"KungFuMasterDeterministic-v0\", render_mode = 'rgb_array')\n",
    "  env = PreprocessAtari(env, height = 42, width = 42, crop = lambda img: img, dim_order = 'pytorch', color = False, n_frames = 4)\n",
    "  return env\n",
    "\n",
    "env = make_env()\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "number_actions = env.action_space.n\n",
    "print(\"Observation shape:\", state_shape)\n",
    "print(\"Number actions:\", number_actions)\n",
    "print(\"Action names:\", env.env.env.get_action_meanings())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF756uIhRVcK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698751393884,
     "user_tz": -60,
     "elapsed": 653,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     }
    },
    "outputId": "50da7ec6-6418-4ad2-fe78-6fdcadb33868"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001B[33mWARN: The environment KungFuMasterDeterministic-v0 is out of date. You should consider upgrading to version `v4`.\u001B[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Observation shape: (4, 42, 42)\n",
      "Number actions: 14\n",
      "Action names: ['NOOP', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'DOWNRIGHT', 'DOWNLEFT', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001B[33mWARN: env.get_action_meanings to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_action_meanings` for environment variables or `env.get_wrapper_attr('get_action_meanings')` that will search the reminding wrappers.\u001B[0m\n",
      "  logger.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing the hyperparameters"
   ],
   "metadata": {
    "id": "YgRlooBmC1hr"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "discount_factor = 0.99\n",
    "num_envs = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing the A3C class"
   ],
   "metadata": {
    "id": "Gg_LmSs9IoTX"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Agent():\n",
    "  \n",
    "  def __init__(self, action_size):\n",
    "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.action_size = action_size\n",
    "    self.network = Network(action_size)\n",
    "    self.optim = optim.Adam(self.network.parameters(), lr=lr)\n",
    "    \n",
    "  def act(self, state):\n",
    "    if state.ndim == 3:\n",
    "      state = [state]\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=self.device)\n",
    "    action_values, _ = self.network(state)\n",
    "    policy = F.softmax(action_values, dim=-1)\n",
    "    return np.array([np.random.choice(len(p), p=p) for p in policy.detach().cpu().numpy()])\n",
    "  \n",
    "  def step(self, state, action, reward, next_state, done):\n",
    "    batch_size = state.shape[0]\n",
    "    state, action, reward, next_state, done = self.__format_tensors(state, action, reward, next_state, done)\n",
    "    action_values, state_value = self.network(state)\n",
    "    _, next_state_value = self.network(next_state)\n",
    "    target_state_value = reward + discount_factor * next_state_value * (1 - done)\n",
    "    advantage = target_state_value - state_value\n",
    "    probs = F.softmax(action_values, dim=-1)\n",
    "    logprobs = F.log_softmax(action_values, dim=-1)\n",
    "    entropy = -torch.sum(probs * logprobs, axis=-1)\n",
    "    batch_idx = np.arange(batch_size)\n",
    "    logp_actions = logprobs[batch_idx, action]\n",
    "    actor_loss = -(logp_actions * advantage.detach()).mean() - 0.001 * entropy.mean()\n",
    "    critic_loss = F.mse_loss(target_state_value.detach(), state_value)\n",
    "    total_loss = actor_loss + critic_loss\n",
    "    self.optim.zero_grad()\n",
    "    total_loss.backward()\n",
    "    self.optim.step()\n",
    "    \n",
    "  def __format_tensors(self, state, action, reward, next_state, done):\n",
    "    def format_tensor(item, dtype=torch.float32):\n",
    "      if type == torch.bool:\n",
    "        return torch.tensor(item, dtype, device=self.device)\n",
    "      return torch.tensor(item, dtype, device=self.device).to(dtype=torch.float32)\n",
    "      \n",
    "    state = format_tensor(item=state)\n",
    "    action = format_tensor(item=action)\n",
    "    reward = format_tensor(item=reward)\n",
    "    next_state = format_tensor(item=next_state)\n",
    "    done = format_tensor(item=done, dtype=torch.bool)\n",
    "      \n",
    "    return state, action, reward, next_state, done\n",
    "      "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T12:32:16.869067Z",
     "start_time": "2024-04-13T12:32:16.859430Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing the A3C agent"
   ],
   "metadata": {
    "id": "7RnRukHDKFJ0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating our A3C agent on a single episode"
   ],
   "metadata": {
    "id": "oB5SpmoKP0aK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing multiple agents on multiple environments at the same time"
   ],
   "metadata": {
    "id": "jVSqiyjiQeMd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the A3C agent"
   ],
   "metadata": {
    "id": "69WZWB4oRx1P"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3 - Visualizing the results"
   ],
   "metadata": {
    "id": "7kG_YR9YdmUM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import imageio\n",
    "from IPython.display import HTML, display\n",
    "from gymnasium.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "\n",
    "def show_video_of_model(agent, env):\n",
    "  state, _ = env.reset()\n",
    "  done = False\n",
    "  frames = []\n",
    "  while not done:\n",
    "    frame = env.render()\n",
    "    frames.append(frame)\n",
    "    action = agent.act(state)\n",
    "    state, reward, done, _, _ = env.step(action[0])\n",
    "  env.close()\n",
    "  imageio.mimsave('video.mp4', frames, fps=30)\n",
    "\n",
    "show_video_of_model(agent, env)\n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display(HTML(data='''<video alt=\"test\" autoplay\n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "show_video()"
   ],
   "metadata": {
    "id": "UGkTuO6DxZ6B"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "19mlgPA6Zj97xML3Mj-8sb0mg8t5W0nmm",
     "timestamp": 1696937661479
    }
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
