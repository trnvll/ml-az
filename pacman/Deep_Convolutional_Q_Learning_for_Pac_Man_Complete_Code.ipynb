{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Convolutional Q-Learning for Pac-Man"
   ],
   "metadata": {
    "id": "EAiHVEoWHy_D"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 0 - Installing the required packages and importing the libraries"
   ],
   "metadata": {
    "id": "tjO1aK3Ddjs5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Installing Gymnasium"
   ],
   "metadata": {
    "id": "NwdRB-ZLdrAV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dbnq3XpoKa_7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fe9d1a88-2931-4986-d34f-f17002bb3c37",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:37:16.304103Z",
     "start_time": "2024-04-08T11:36:28.676833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 23.7.4\r\n",
      "  latest version: 24.3.0\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "Or to minimize the number of packages updated during conda update use\r\n",
      "\r\n",
      "     conda install conda=24.3.0\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 23.7.4\r\n",
      "  latest version: 24.3.0\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "Or to minimize the number of packages updated during conda update use\r\n",
      "\r\n",
      "     conda install conda=24.3.0\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n",
      "fish: Unknown command: apt-get\r\n",
      "fish: \r\n",
      "apt-get install -y swig\r\n",
      "^\r\n",
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 23.7.4\r\n",
      "  latest version: 24.3.0\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "Or to minimize the number of packages updated during conda update use\r\n",
      "\r\n",
      "     conda install conda=24.3.0\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# All requested packages already installed.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda install gymnasium\n",
    "!conda install \"gymnasium[atari, accept-rom-license]\"\n",
    "!apt-get install -y swig\n",
    "!conda install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing the libraries"
   ],
   "metadata": {
    "id": "H-wes4LZdxdd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ho_25-9_9qnu",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:37:16.308346Z",
     "start_time": "2024-04-08T11:37:16.305464Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from pipe import select\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1 - Building the AI"
   ],
   "metadata": {
    "id": "m7wa0ft8e3M_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating the architecture of the Neural Network"
   ],
   "metadata": {
    "id": "dlYVpVdHe-i6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "  def __init__(self, action_size, seed = 42):\n",
    "    super(Network, self).__init__()\n",
    "    self.seed = torch.manual_seed(seed)\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size = 8, stride = 4)\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size = 4, stride = 2)\n",
    "    self.bn2 = nn.BatchNorm2d(64)\n",
    "    self.conv3 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1)\n",
    "    self.bn3 = nn.BatchNorm2d(64)\n",
    "    self.conv4 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1)\n",
    "    self.bn4 = nn.BatchNorm2d(128)\n",
    "    self.fc1 = nn.Linear(10 * 10 * 128, 512)\n",
    "    self.fc2 = nn.Linear(512, 256)\n",
    "    self.fc3 = nn.Linear(256, action_size)\n",
    "\n",
    "  def forward(self, state):\n",
    "    x = F.relu(self.bn1(self.conv1(state)))\n",
    "    x = F.relu(self.bn2(self.conv2(x)))\n",
    "    x = F.relu(self.bn3(self.conv3(x)))\n",
    "    x = F.relu(self.bn4(self.conv4(x)))\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    return self.fc3(x)\n",
    "    \n",
    "      "
   ],
   "metadata": {
    "id": "4ZW9ybp2S-op",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:37:16.313884Z",
     "start_time": "2024-04-08T11:37:16.309299Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2 - Training the AI"
   ],
   "metadata": {
    "id": "rUvCfE_mhwo2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up the environment"
   ],
   "metadata": {
    "id": "WWCDPF22lkwc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make('MsPacmanDeterministic-v0', full_action_space=False)\n",
    "state_shape = env.observation_space.shape\n",
    "state_size = state_shape[0]\n",
    "n_actions = env.action_space.n\n",
    "print(f\"State shape: {state_shape}\")\n",
    "print(f\"State size: {state_size}\")\n",
    "print(f\"Number of actions: {n_actions}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYLnz2Z6PqeU",
    "outputId": "e8c43b31-b4a1-4650-ad15-562d5e27f151",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:37:16.373046Z",
     "start_time": "2024-04-08T11:37:16.315613Z"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape: (210, 160, 3)\n",
      "State size: 210\n",
      "Number of actions: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandertornvall/anaconda3/envs/az/lib/python3.8/site-packages/gymnasium/envs/registration.py:523: DeprecationWarning: \u001B[33mWARN: The environment MsPacmanDeterministic-v0 is out of date. You should consider upgrading to version `v4`.\u001B[0m\n",
      "  logger.deprecation(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing the hyperparameters"
   ],
   "metadata": {
    "id": "Bx6IdX3ciDqH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lr = 5e-4\n",
    "minibatch_size = 64\n",
    "discount_factor = 0.99"
   ],
   "metadata": {
    "id": "pQHWLxOwrb0J",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9716170b-77bd-4767-81eb-4be906fbb5ea",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:37:16.376230Z",
     "start_time": "2024-04-08T11:37:16.374145Z"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing the frames"
   ],
   "metadata": {
    "id": "U2bDShIEkA5V"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "  frame = Image.fromarray(frame)\n",
    "  preprocess = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n",
    "  return preprocess(frame).unsqueeze(0)"
   ],
   "metadata": {
    "id": "VporQhgMDygL",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:37:16.379605Z",
     "start_time": "2024-04-08T11:37:16.377035Z"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementing the DCQN class"
   ],
   "metadata": {
    "id": "imMdSO-HAWra"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Agent():\n",
    "\n",
    "    def __init__(self, action_size):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.local_qnetwork = Network(action_size).to(self.device)\n",
    "        self.target_qnetwork = Network(action_size).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.local_qnetwork.parameters(), lr=lr)\n",
    "        self.memory = deque(maxlen=10_000)\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        state = preprocess_frame(state)\n",
    "        next_state = preprocess_frame(next_state)\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if len(self.memory) > minibatch_size:\n",
    "            xps = random.sample(self.memory, k=minibatch_size)\n",
    "            self.learn(xps, discount_factor)\n",
    "\n",
    "    def act(self, state, epsilon=0.):\n",
    "        state = preprocess_frame(state).to(self.device)\n",
    "        self.local_qnetwork.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.local_qnetwork(state)\n",
    "        self.local_qnetwork.train()\n",
    "\n",
    "        if random.random() > epsilon:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, xps, discount_factor):\n",
    "        states, actions, rewards, next_states, dones = zip(*xps)\n",
    "        \n",
    "        states = torch.from_numpy(np.vstack(states)).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack(actions)).long().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack(rewards)).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack(next_states)).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack(dones).astype(np.uint8)).float().to(self.device)\n",
    "        \n",
    "        next_q_targets = self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        q_targets = rewards + (discount_factor * next_q_targets * (1 - dones))\n",
    "        q_expected = self.local_qnetwork(states).gather(1, actions)\n",
    "        loss = F.mse_loss(q_expected, q_targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ],
   "metadata": {
    "id": "N7dwS2q2wupJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a2c2d99d-760c-47fb-c21a-546230e9403d",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:37:16.386831Z",
     "start_time": "2024-04-08T11:37:16.380480Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing the DCQN agent"
   ],
   "metadata": {
    "id": "yUg95iBpAwII"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "agent = Agent(n_actions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T11:37:16.445207Z",
     "start_time": "2024-04-08T11:37:16.387780Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the DCQN agent"
   ],
   "metadata": {
    "id": "CK6Zt_gNmHvm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "n_episodes = 2_000\n",
    "max_n_timesteps_per_episode = 10_000\n",
    "epsilon_starting = 1.0\n",
    "epsilon_ending = 0.01\n",
    "epsilon_decay = 0.995\n",
    "epsilon = epsilon_starting\n",
    "scores_on_100_episodes = deque(maxlen=100)\n",
    "solved_n_scores = 500\n",
    "\n",
    "for episode in range(1, n_episodes + 1):\n",
    "    state, _ = env.reset()\n",
    "    score = 0\n",
    "    for t in range(max_n_timesteps_per_episode):\n",
    "        action = agent.act(state, epsilon)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "        score += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    scores_on_100_episodes.append(score)\n",
    "    epsilon = max(epsilon_ending, epsilon * epsilon_decay)\n",
    "\n",
    "    print('\\rEpisode {}\\tAverage score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)), end=\"\")\n",
    "    if episode % 100 == 0:\n",
    "        print('\\rEpisode {}\\tAverage score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)))\n",
    "\n",
    "    if np.mean(scores_on_100_episodes) >= solved_n_scores:\n",
    "        print('\\nEnvironment solved in {:d} episodes!\\tAverage score: {:.2f}'.format(episode - 100, np.mean(scores_on_100_episodes)))\n",
    "        torch.save(agent.local_qnetwork.state_dict(), 'checkpoint.pth')\n",
    "        break\n"
   ],
   "metadata": {
    "id": "XvBh4TLjIfz2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "732fc6f1-6f78-4348-f888-b170f2bbcfb3",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:38:33.106902Z",
     "start_time": "2024-04-08T11:37:16.446211Z"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m action \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mact(state, epsilon)\n\u001B[1;32m     15\u001B[0m next_state, reward, done, _, _ \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[0;32m---> 16\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m state \u001B[38;5;241m=\u001B[39m next_state\n\u001B[1;32m     19\u001B[0m score \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m reward\n",
      "Cell \u001B[0;32mIn[26], line 18\u001B[0m, in \u001B[0;36mAgent.step\u001B[0;34m(self, state, action, reward, next_state, done)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory) \u001B[38;5;241m>\u001B[39m minibatch_size:\n\u001B[1;32m     17\u001B[0m     xps \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory, k\u001B[38;5;241m=\u001B[39mminibatch_size)\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdiscount_factor\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[26], line 41\u001B[0m, in \u001B[0;36mAgent.learn\u001B[0;34m(self, xps, discount_factor)\u001B[0m\n\u001B[1;32m     38\u001B[0m next_states \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(np\u001B[38;5;241m.\u001B[39mvstack(next_states))\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     39\u001B[0m dones \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(np\u001B[38;5;241m.\u001B[39mvstack(dones)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8))\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 41\u001B[0m next_q_targets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_qnetwork\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnext_states\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     42\u001B[0m q_targets \u001B[38;5;241m=\u001B[39m rewards \u001B[38;5;241m+\u001B[39m (discount_factor \u001B[38;5;241m*\u001B[39m next_q_targets \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m dones))\n\u001B[1;32m     43\u001B[0m q_expected \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_qnetwork(states)\u001B[38;5;241m.\u001B[39mgather(\u001B[38;5;241m1\u001B[39m, actions)\n",
      "File \u001B[0;32m~/anaconda3/envs/az/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/az/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[22], line 20\u001B[0m, in \u001B[0;36mNetwork.forward\u001B[0;34m(self, state)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, state):\n\u001B[1;32m     19\u001B[0m   x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(state)))\n\u001B[0;32m---> 20\u001B[0m   x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m     21\u001B[0m   x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn3(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3(x)))\n\u001B[1;32m     22\u001B[0m   x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn4(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv4(x)))\n",
      "File \u001B[0;32m~/anaconda3/envs/az/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/az/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/az/lib/python3.8/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/az/lib/python3.8/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3 - Visualizing the results"
   ],
   "metadata": {
    "id": "-0WhhBV8nQdf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb9nVvU2Okhk",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "outputId": "c70e6829-1c12-4ea3-8a3b-eb57308a9056",
    "ExecuteTime": {
     "end_time": "2024-04-08T11:38:33.107750Z",
     "start_time": "2024-04-08T11:38:33.107696Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import imageio\n",
    "from IPython.display import HTML, display\n",
    "from gymnasium.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/opt/homebrew/bin/ffmpeg\"\n",
    "\n",
    "def show_video_of_model(agent: Agent, env_name):\n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    frames = []\n",
    "    while not done:\n",
    "        frame = env.render()\n",
    "        frames.append(frame)\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _, _ = env.step(action.item())\n",
    "    env.close()\n",
    "    imageio.mimsave('video.mp4', frames, fps=30)\n",
    "\n",
    "show_video_of_model(agent, 'MsPacmanDeterministic-v0')\n",
    "\n",
    "def show_video():\n",
    "    video_list = glob.glob('*.mp4')\n",
    "    if len(video_list) > 0:\n",
    "        most_recent_vid = video_list[0]\n",
    "        video = io.open(most_recent_vid, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display(HTML(data='''<video alt=\"test\" autoplay loop controls style=\"height:384px;\"><source src=\"data:video/mp4;base64,{0}\" /></video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print('Could not find video.')\n",
    "\n",
    "show_video()\n",
    "        \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "V100"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
